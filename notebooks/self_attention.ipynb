{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10504395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghass\\.virtualenvs\\llm_from_scratch-Nm31MAtF\\lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:276: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb5110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0043a18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_in: 3\n",
      "d_out: 2\n"
     ]
    }
   ],
   "source": [
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2\n",
    "print('d_in:',d_in)\n",
    "print('d_out:',d_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74177c05",
   "metadata": {},
   "source": [
    "Note: in GPT-like models, the input and output dimensions are usually the same. Here we chose that the dimensions are not the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca17995",
   "metadata": {},
   "source": [
    "We will initialize the three weight matrices Wq,Wk and Wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "951b41e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "w_query = torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "w_key = torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "w_value = torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86583638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.2961, 0.5166],\n",
      "        [0.2517, 0.6886],\n",
      "        [0.0740, 0.8665]])\n"
     ]
    }
   ],
   "source": [
    "print(w_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0e6b50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.1366, 0.1025],\n",
      "        [0.1841, 0.7264],\n",
      "        [0.3153, 0.6871]])\n"
     ]
    }
   ],
   "source": [
    "print(w_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e5ba5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.0756, 0.1966],\n",
      "        [0.3164, 0.4017],\n",
      "        [0.1186, 0.8274]])\n"
     ]
    }
   ],
   "source": [
    "print(w_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a15191d",
   "metadata": {},
   "source": [
    "Now, we can get the query,key and value matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeadc530",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_2 = x_2 @ w_query\n",
    "k_2 = x_2 @ w_key\n",
    "v_2 = x_2 @ w_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b83ffa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n"
     ]
    }
   ],
   "source": [
    "print(q_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252acf12",
   "metadata": {},
   "source": [
    "We can now generalize to all the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f53b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = inputs @ w_query\n",
    "keys = inputs @ w_key\n",
    "values = inputs @ w_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5938c050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2309, 1.0966],\n",
      "        [0.4306, 1.4551],\n",
      "        [0.4300, 1.4343],\n",
      "        [0.2355, 0.7990],\n",
      "        [0.2983, 0.6565],\n",
      "        [0.2568, 1.0533]])\n"
     ]
    }
   ],
   "source": [
    "print(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cec7ecb",
   "metadata": {},
   "source": [
    "Now let's compute the attension score w22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fb7f23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8524)\n"
     ]
    }
   ],
   "source": [
    "keys_2 = keys[1]\n",
    "attn_score_22 = q_2.dot(keys_2)\n",
    "print(attn_score_22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95866b77",
   "metadata": {},
   "source": [
    "Computing attention score between the second query (\"journey\") and all keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e5bd7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
     ]
    }
   ],
   "source": [
    "attn_score_2 = q_2 @ keys.T\n",
    "print(attn_score_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a158da6",
   "metadata": {},
   "source": [
    "We can generalize all attention scores of the queries and keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f45bfbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9231, 1.3545, 1.3241, 0.7910, 0.4032, 1.1330],\n",
      "        [1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440],\n",
      "        [1.2544, 1.8284, 1.7877, 1.0654, 0.5508, 1.5238],\n",
      "        [0.6973, 1.0167, 0.9941, 0.5925, 0.3061, 0.8475],\n",
      "        [0.6114, 0.8819, 0.8626, 0.5121, 0.2707, 0.7307],\n",
      "        [0.8995, 1.3165, 1.2871, 0.7682, 0.3937, 1.0996]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = queries @ keys.T \n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a00b34",
   "metadata": {},
   "source": [
    "Computing the attention weights by scaling the attention scores and using the softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "972b9d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "d_keys = keys.shape[-1]\n",
    "attn_weights_2 = torch.softmax(attn_score_2/d_keys**0.5,dim=-1)\n",
    "print(attn_weights_2)\n",
    "print(d_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd0c39f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1551, 0.2104, 0.2059, 0.1413, 0.1074, 0.1799],\n",
      "        [0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820],\n",
      "        [0.1503, 0.2256, 0.2192, 0.1315, 0.0914, 0.1819],\n",
      "        [0.1591, 0.1994, 0.1962, 0.1477, 0.1206, 0.1769],\n",
      "        [0.1610, 0.1949, 0.1923, 0.1501, 0.1265, 0.1752],\n",
      "        [0.1557, 0.2092, 0.2048, 0.1419, 0.1089, 0.1794]])\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores/d_keys**0.5,dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd2d618",
   "metadata": {},
   "source": [
    "Dividing by sqrt(keys_dim):\n",
    "* For stability in learning: the softmax function is sensitive to the magnitude of its inputs. When the inputs are large, the differences between the exponential values of each input value are much more pronounced. This causes the softmax output to become \"peaky\". Where the highest value receives almost all the probability mass.\n",
    "* Particularly in transformers, if the dot products between query and key vectors become too large, the attention score becomes very large. This results in a very sharp softmax distribution, making the model overly confident in one particular key.\n",
    "* It is also useful to make the variance of the dot product stable.\n",
    "* The dot product of Q and K increases the variance because multiplying two random numbers increases the variance.\n",
    "* This variance increases if the dimension grows.\n",
    "* Dividing by sqrt(dim) keeps the variance close to one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f32572a",
   "metadata": {},
   "source": [
    "Final step is to compute the context vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49814d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]])\n"
     ]
    }
   ],
   "source": [
    "context_vecs = attn_weights @ values\n",
    "print(context_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3bf806",
   "metadata": {},
   "source": [
    "Implementing a compact self attention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "940d14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self,d_in,d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_key = nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in,d_out))\n",
    "    def forward(self,x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "        \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores/keys.shape[-1]**0.5,dim=-1\n",
    "        )\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b329320",
   "metadata": {},
   "source": [
    "* SelfAttention_v1 is a class derived from nn.Module, which is a fundamental building block of PyTorch models and that provides necessary functionalities for model layer creation and management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c9efa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in,d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30cdc21",
   "metadata": {},
   "source": [
    "We can improve the SelfAttention_V1 by utilizing PyTorch's nn.Linear layers, which effectively perform matrix multiplication when the bias units are disabled.\n",
    "* nn.Linear has an optimized weight initialization scheme, contributing to more stable and effective model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32bbf364",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v2(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_in,d_out,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_query(x)\n",
    "        \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores/keys.shape[-1]**0.5,dim=-1)\n",
    "        context_vec = attn_weights @ values\n",
    "        \n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f8ccc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6729, -0.3148],\n",
      "        [ 0.6757, -0.3146],\n",
      "        [ 0.6757, -0.3146],\n",
      "        [ 0.6750, -0.3164],\n",
      "        [ 0.6749, -0.3168],\n",
      "        [ 0.6752, -0.3157]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in,d_out)\n",
    "print(sa_v2(inputs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_from_scratch-Nm31MAtF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
